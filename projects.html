

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="./">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Projects &mdash; SC2 Benchmark v0.1.2-dev documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="_static/css/theme.css?v=e59714d7" />

  
      <script src="_static/jquery.js?v=5d32c60e"></script>
      <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="_static/documentation_options.js?v=3f9519be"></script>
      <script src="_static/doctools.js?v=9bcbadda"></script>
      <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="sc2bench.analysis" href="subpkgs/analysis.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            SC2 Benchmark
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">üìö Overview</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="usage.html">Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="package.html">sc2bench API</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">üßëüèª‚Äçüíª Research</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Projects</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#papers">Papers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#a-novel-middleware-for-adaptive-and-efficient-split-computing-for-real-time-object-detection">A novel middleware for adaptive and efficient split computing for real-time object detection</a></li>
<li class="toctree-l3"><a class="reference internal" href="#a-multi-task-supervised-compression-model-for-split-computing">A Multi-task Supervised Compression Model for Split Computing</a></li>
<li class="toctree-l3"><a class="reference internal" href="#frankensplit-efficient-neural-feature-compression-with-shallow-variational-bottleneck-injection-for-mobile-edge-computing">FrankenSplit: Efficient Neural Feature Compression With Shallow Variational Bottleneck Injection for Mobile Edge Computing</a></li>
<li class="toctree-l3"><a class="reference internal" href="#resilience-of-entropy-model-in-distributed-neural-networks">Resilience of Entropy Model in Distributed Neural Networks</a></li>
<li class="toctree-l3"><a class="reference internal" href="#sc2-benchmark-supervised-compression-for-split-computing">SC2 Benchmark: Supervised Compression for Split Computing</a></li>
</ul>
</li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">SC2 Benchmark</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content style-external-links">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Projects</li>
      <li class="wy-breadcrumbs-aside">
              <a href="https://github.com/yoshitomo-matsubara/sc2-benchmark/blob/main/docs/source/projects.rst" class="fa fa-github"> Edit on GitHub</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="projects">
<h1>Projects<a class="headerlink" href="#projects" title="Link to this heading">ÔÉÅ</a></h1>
<div class="toctree-wrapper compound">
</div>
<p>This page is a showcase of OSS (open source software) and papers which have used <strong>sc2bench</strong> in the projects.
If your work is built on <strong>sc2bench</strong>, start <a class="reference external" href="https://github.com/yoshitomo-matsubara/sc2-benchmark/discussions/new?category=show-and-tell">a ‚ÄúShow and tell‚Äù discussion at GitHub</a>.</p>
<section id="papers">
<h2>Papers<a class="headerlink" href="#papers" title="Link to this heading">ÔÉÅ</a></h2>
<section id="a-novel-middleware-for-adaptive-and-efficient-split-computing-for-real-time-object-detection">
<h3>A novel middleware for adaptive and efficient split computing for real-time object detection<a class="headerlink" href="#a-novel-middleware-for-adaptive-and-efficient-split-computing-for-real-time-object-detection" title="Link to this heading">ÔÉÅ</a></h3>
<ul class="simple">
<li><p>Author(s): Matteo Mendula, Paolo Bellavista, Marco Levorato, Sharon Ladron de Guevara Contreras</p></li>
<li><p>Venue: Pervasive and Mobile Computing Journal</p></li>
<li><p>PDF: <a class="reference external" href="https://www.sciencedirect.com/science/article/pii/S1574119225000173?via%3Dihub">Paper</a></p></li>
<li><p>Dataset: <a class="reference external" href="https://github.com/MatteoMendula/FurciferDataset">GitHub</a></p></li>
</ul>
<p>Real-world applications requiring real-time responsiveness frequently rely on energy-intensive and compute-heavy neural network algorithms. Strategies include deploying distributed and optimized Deep Neural Networks on mobile devices, which can lead to considerable energy consumption and degraded performance, or offloading larger models to edge servers, which requires low-latency wireless channels. Here we present Furcifer, a novel middleware that autonomously adjusts the computing strategy (i.e., local computing, edge computing, or split computing) based on context conditions. Utilizing container-based services and low-complexity predictors that generalize across environments, Furcifer supports supervised compression as a viable alternative to pure local or remote processing in real-time environments. An extensive set of experiments coversdiverse scenarios, including both stable and highly dynamic channel environments with unpredictable changes in connection quality and load. In moderate-varying scenarios, Furcifer demonstrates significant benefits: achieving a 2x reduction in energy consumption, a 30% higher mean Average Precision score compared to local computing, and a three-fold FPS increase over static offloading. In highly dynamic environments with unreliable connectivity and rapid increases in concurrent clients, Furcifer‚Äôs predictive capabilities preserves up to 30% energy, achieving a 16% higher accuracy rate, and completing 80% more frame inferences compared to pure local computing and approaches without trend forecasting, respectively.</p>
</section>
<section id="a-multi-task-supervised-compression-model-for-split-computing">
<h3>A Multi-task Supervised Compression Model for Split Computing<a class="headerlink" href="#a-multi-task-supervised-compression-model-for-split-computing" title="Link to this heading">ÔÉÅ</a></h3>
<ul class="simple">
<li><p>Author(s): Yoshitomo Matsubara, Matteo Mendula, Marco Levorato</p></li>
<li><p>Venue: WACV 2025</p></li>
<li><p>PDF: <a class="reference external" href="https://arxiv.org/abs/2501.01420">Paper</a></p></li>
<li><p>Code: <a class="reference external" href="https://github.com/yoshitomo-matsubara/ladon-multi-task-sc2">GitHub</a></p></li>
</ul>
<p>Split computing (‚â† split learning) is a promising approach to deep learning models for resource-constrained
edge computing systems, where weak sensor (mobile) devices are wirelessly connected to stronger edge servers through
channels with limited communication capacity. State-of-theart work on split computing presents methods for single tasks
such as image classification, object detection, or semantic segmentation. The application of existing methods to
multitask problems degrades model accuracy and/or significantly increase runtime latency. In this study, we propose Ladon,
the first multi-task-head supervised compression model for multi-task split computing. Experimental results show that
the multi-task supervised compression model either outperformed or rivaled strong lightweight baseline models in terms
of predictive performance for ILSVRC 2012, COCO 2017, and PASCAL VOC 2012 datasets while learning compressed
representations at its early layers. Furthermore, our models reduced end-to-end latency (by up to 95.4%) and
energy consumption of mobile devices (by up to 88.2%) in multi-task split computing scenarios.</p>
</section>
<section id="frankensplit-efficient-neural-feature-compression-with-shallow-variational-bottleneck-injection-for-mobile-edge-computing">
<h3>FrankenSplit: Efficient Neural Feature Compression With Shallow Variational Bottleneck Injection for Mobile Edge Computing<a class="headerlink" href="#frankensplit-efficient-neural-feature-compression-with-shallow-variational-bottleneck-injection-for-mobile-edge-computing" title="Link to this heading">ÔÉÅ</a></h3>
<ul class="simple">
<li><p>Author(s): Alireza Furutanpey, Philipp Raith, Schahram Dustdar</p></li>
<li><p>Venue: IEEE Transactions on Mobile Computing</p></li>
<li><p>PDF: <a class="reference external" href="https://ieeexplore.ieee.org/document/10480247/">Paper</a></p></li>
<li><p>Code: <a class="reference external" href="https://github.com/rezafuru/FrankenSplit">GitHub</a></p></li>
</ul>
<p><strong>Abstract</strong>: The rise of mobile AI accelerators allows latency-sensitive applications to execute lightweight Deep Neural
Networks (DNNs) on the client side. However, critical applications require powerful models that edge devices cannot host
and must therefore offload requests, where the high-dimensional data will compete for limited bandwidth.
Split Computing (SC) alleviates resource inefficiency by partitioning DNN layers across devices, but current methods are
overly specific and only marginally reduce bandwidth consumption. This work proposes shifting away from focusing on
executing shallow layers of partitioned DNNs. Instead, it advocates concentrating the local resources on variational
compression optimized for machine interpretability. We introduce a novel framework for resource-conscious compression
models and extensively evaluate our method in an environment reflecting the asymmetric resource distribution between edge
devices and servers. Our method achieves 60% lower bitrate than a state-of-the-art SC method without decreasing accuracy
and is up to 16x faster than offloading with existing codec standards.</p>
</section>
<section id="resilience-of-entropy-model-in-distributed-neural-networks">
<h3>Resilience of Entropy Model in Distributed Neural Networks<a class="headerlink" href="#resilience-of-entropy-model-in-distributed-neural-networks" title="Link to this heading">ÔÉÅ</a></h3>
<ul class="simple">
<li><p>Author(s): Milin Zhang, Mohammad Abdi, Shahriar Rifat, Francesco Restuccia</p></li>
<li><p>Venue: ECCV 2024</p></li>
<li><p>PDF: <a class="reference external" href="https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/03193.pdf">Paper</a></p></li>
<li><p>Code: <a class="reference external" href="https://github.com/Restuccia-Group/EntropyR">GitHub</a></p></li>
</ul>
<p><strong>Abstract</strong>: Distributed deep neural networks (DNNs) have emerged as a key technique to reduce communication overhead
without sacrificing performance in edge computing systems. Recently, entropy coding has been introduced to further
reduce the communication overhead. The key idea is to train the distributed DNN jointly with an entropy model,
which is used as side information during inference time to adaptively encode latent representations into bit streams
with variable length. To the best of our knowledge, the resilience of entropy models is yet to be investigated.
As such, in this paper we formulate and investigate the resilience of entropy models to intentional interference
(e.g., adversarial attacks) and unintentional interference (e.g., weather changes and motion blur).
Through an extensive experimental campaign with 3 different DNN architectures, 2 entropy models and 4 rate-distortion
tradeoff factors, we demonstrate that the entropy attacks can increase the communication overhead by up to 95%.
By separating compression features in frequency and spatial domain, we propose a new defense mechanism that can reduce
the transmission overhead of the attacked input by about 9% compared to unperturbed data, with only about 2% accuracy
loss. Importantly, the proposed defense mechanism is a standalone approach which can be applied in conjunction with
approaches such as adversarial training to further improve robustness. Code is available at <a class="reference external" href="https://github.com/Restuccia-Group/EntropyR">https://github.com/Restuccia-Group/EntropyR</a>.</p>
</section>
<section id="sc2-benchmark-supervised-compression-for-split-computing">
<h3>SC2 Benchmark: Supervised Compression for Split Computing<a class="headerlink" href="#sc2-benchmark-supervised-compression-for-split-computing" title="Link to this heading">ÔÉÅ</a></h3>
<ul class="simple">
<li><p>Author(s): Yoshitomo Matsubara, Ruihan Yang, Marco Levorato, Stephan Mandt</p></li>
<li><p>Venue: TMLR</p></li>
<li><p>PDF: <a class="reference external" href="https://openreview.net/forum?id=p28wv4G65d">Paper + Supp</a></p></li>
<li><p>Code: <a class="reference external" href="https://github.com/yoshitomo-matsubara/sc2-benchmark">GitHub</a></p></li>
</ul>
<p><strong>Abstract</strong>: With the increasing demand for deep learning models on mobile devices, splitting neural network
computation between the device and a more powerful edge server has become an attractive solution. However, existing
split computing approaches often underperform compared to a naive baseline of remote computation on compressed data.
Recent studies propose learning compressed representations that contain more relevant information for supervised
downstream tasks, showing improved tradeoffs between compressed data size and supervised performance. However, existing
evaluation metrics only provide an incomplete picture of split computing. This study introduces supervised compression
for split computing (SC2) and proposes new evaluation criteria: minimizing computation on the mobile device, minimizing
transmitted data size, and maximizing model accuracy. We conduct a comprehensive benchmark study using 10 baseline
methods, three computer vision tasks, and over 180 trained models, and discuss various aspects of SC2. We also release
our code and sc2bench, a Python package for future research on SC2. Our proposed metrics and package will help
researchers better understand the tradeoffs of supervised compression in split computing.</p>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="subpkgs/analysis.html" class="btn btn-neutral float-left" title="sc2bench.analysis" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, Yoshitomo Matsubara.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
    <!-- Theme Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-39T9X4DN85"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-39T9X4DN85', {
          'anonymize_ip': false,
      });
    </script> 

</body>
</html>